{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:18:42.554405Z","iopub.execute_input":"2023-12-27T08:18:42.554811Z","iopub.status.idle":"2023-12-27T08:18:54.208029Z","shell.execute_reply.started":"2023-12-27T08:18:42.554780Z","shell.execute_reply":"2023-12-27T08:18:54.206988Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:20:06.878918Z","iopub.execute_input":"2023-12-27T08:20:06.879613Z","iopub.status.idle":"2023-12-27T08:20:18.536988Z","shell.execute_reply.started":"2023-12-27T08:20:06.879575Z","shell.execute_reply":"2023-12-27T08:20:18.535795Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader,Dataset\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:20:18.656104Z","iopub.execute_input":"2023-12-27T08:20:18.656519Z","iopub.status.idle":"2023-12-27T08:20:22.531030Z","shell.execute_reply.started":"2023-12-27T08:20:18.656488Z","shell.execute_reply":"2023-12-27T08:20:22.530164Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer,BertForSequenceClassification\n\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=6)\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:20:22.532583Z","iopub.execute_input":"2023-12-27T08:20:22.532974Z","iopub.status.idle":"2023-12-27T08:20:28.677529Z","shell.execute_reply.started":"2023-12-27T08:20:22.532947Z","shell.execute_reply":"2023-12-27T08:20:28.676724Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1f2f499dd14ed59a0b69ac84023f15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1983923eaa40ee988f642c4ff0444c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d305e8f5bfba4dc79da2ad01e17d9a29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"848c724b3c824ba29a6effdd5a572753"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abb2306d0d2414fa87a817149aade66"}},"metadata":{}}]},{"cell_type":"code","source":"print(model.parameters)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:35:50.937258Z","iopub.execute_input":"2023-12-27T08:35:50.937659Z","iopub.status.idle":"2023-12-27T08:35:50.945089Z","shell.execute_reply.started":"2023-12-27T08:35:50.937624Z","shell.execute_reply":"2023-12-27T08:35:50.943941Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<bound method Module.parameters of BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)>\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# dataset = load_dataset(\"SetFit/emotion\")\n# from datasets import load_dataset\n\ndataset = load_dataset(\"dair-ai/emotion\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:35:53.583023Z","iopub.execute_input":"2023-12-27T08:35:53.583412Z","iopub.status.idle":"2023-12-27T08:35:57.910958Z","shell.execute_reply.started":"2023-12-27T08:35:53.583379Z","shell.execute_reply":"2023-12-27T08:35:57.910030Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9023ccc935248dfa651ec7362f79aa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/3.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714042622fd54fb5a84bf98ca184a981"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset emotion/split to /root/.cache/huggingface/datasets/dair-ai___emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b5493ed7fc4ca8b3c2e5a0a9ae0edc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/592k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd1c4f1d2494ee0a65ab4580efc9568"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/74.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3efaaca482f3413aa6d805ee3738d7bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/74.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98163cfcf4d4747bd5a10d1624f9a51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac086e0842e74f06a656d3432d0c1fe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/dair-ai___emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"704c96ec5f1a407b8c17027142ff7394"}},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer(['hello world'],padding=\"max_length\",truncation=True,return_tensors=\"pt\",max_length=128)\ninputs","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:01.871791Z","iopub.execute_input":"2023-12-27T08:36:01.872209Z","iopub.status.idle":"2023-12-27T08:36:01.883770Z","shell.execute_reply.started":"2023-12-27T08:36:01.872175Z","shell.execute_reply":"2023-12-27T08:36:01.882851Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 101, 7592, 2088,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"outputs = model(inputs['input_ids'])\noutputs","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:04.061514Z","iopub.execute_input":"2023-12-27T08:36:04.062165Z","iopub.status.idle":"2023-12-27T08:36:04.744365Z","shell.execute_reply.started":"2023-12-27T08:36:04.062133Z","shell.execute_reply":"2023-12-27T08:36:04.743379Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0434, -0.3377,  0.1346, -0.4797, -0.0717, -0.4622]],\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:06.202694Z","iopub.execute_input":"2023-12-27T08:36:06.203316Z","iopub.status.idle":"2023-12-27T08:36:06.210416Z","shell.execute_reply.started":"2023-12-27T08:36:06.203272Z","shell.execute_reply":"2023-12-27T08:36:06.209363Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def process_data(sample,padding=\"max_length\"):\n#     inputs = [item for item in sample['text']]\n    \n    X = tokenizer(text_target=sample['text'],padding=padding,max_length=128,truncation=True)\n    \n    X[\"labels\"] = sample[\"label\"]\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:08.361873Z","iopub.execute_input":"2023-12-27T08:36:08.362251Z","iopub.status.idle":"2023-12-27T08:36:08.367647Z","shell.execute_reply.started":"2023-12-27T08:36:08.362220Z","shell.execute_reply":"2023-12-27T08:36:08.366583Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # dataset['train'][:1000]\n# dataset['train'] = dataset['train'][:2000]\n# dataset['test'] = dataset['test'][:1000]","metadata":{"execution":{"iopub.status.busy":"2023-12-26T17:52:03.730877Z","iopub.execute_input":"2023-12-26T17:52:03.731450Z","iopub.status.idle":"2023-12-26T17:52:03.742558Z","shell.execute_reply.started":"2023-12-26T17:52:03.731422Z","shell.execute_reply":"2023-12-26T17:52:03.741764Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset['train'].map(process_data,batched=True,remove_columns=['text','label'])\ntest_dataset = dataset['test'].map(process_data,batched=True,remove_columns=['text','label'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:09.578035Z","iopub.execute_input":"2023-12-27T08:36:09.578448Z","iopub.status.idle":"2023-12-27T08:36:23.776897Z","shell.execute_reply.started":"2023-12-27T08:36:09.578417Z","shell.execute_reply":"2023-12-27T08:36:23.776045Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d3084b515e54f818f3dfe350d187f20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d206f8e93a914c12b8e19769308c41a1"}},"metadata":{}}]},{"cell_type":"code","source":"torch.tensor(train_dataset['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:24.935762Z","iopub.execute_input":"2023-12-27T08:36:24.936614Z","iopub.status.idle":"2023-12-27T08:36:26.368169Z","shell.execute_reply.started":"2023-12-27T08:36:24.936579Z","shell.execute_reply":"2023-12-27T08:36:26.367161Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"model(torch.tensor([train_dataset['input_ids'][0]]))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:32.713303Z","iopub.execute_input":"2023-12-27T08:36:32.713675Z","iopub.status.idle":"2023-12-27T08:36:34.540533Z","shell.execute_reply.started":"2023-12-27T08:36:32.713645Z","shell.execute_reply":"2023-12-27T08:36:34.539397Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"SequenceClassifierOutput(loss=None, logits=tensor([[-0.0045, -0.2823,  0.1871, -0.4061, -0.0765, -0.4042]],\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset_d = train_dataset.select(range(100))\ntest_dataset_d = test_dataset.select(range(100))\n\ntrain_dataset_d","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:34.542501Z","iopub.execute_input":"2023-12-27T08:36:34.543158Z","iopub.status.idle":"2023-12-27T08:36:34.557685Z","shell.execute_reply.started":"2023-12-27T08:36:34.543104Z","shell.execute_reply":"2023-12-27T08:36:34.556826Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 100\n})"},"metadata":{}}]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self,model,num_classes):\n        super(BertClassifier,self).__init__()\n        self.model = model\n        \n    def forward(self,x):\n        x = self.model(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:43.083152Z","iopub.execute_input":"2023-12-27T08:36:43.084024Z","iopub.status.idle":"2023-12-27T08:36:43.089157Z","shell.execute_reply.started":"2023-12-27T08:36:43.083989Z","shell.execute_reply":"2023-12-27T08:36:43.088165Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_0 = BertClassifier(model,6)\nmodel_0.to(device)\nprint(model_0.parameters)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:36:45.101392Z","iopub.execute_input":"2023-12-27T08:36:45.101754Z","iopub.status.idle":"2023-12-27T08:36:48.768504Z","shell.execute_reply.started":"2023-12-27T08:36:45.101727Z","shell.execute_reply":"2023-12-27T08:36:48.767511Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<bound method Module.parameters of BertClassifier(\n  (model): BertForSequenceClassification(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (classifier): Linear(in_features=768, out_features=6, bias=True)\n  )\n)>\n","output_type":"stream"}]},{"cell_type":"code","source":"def accuracy(y_pred,y_true):\n    return sum((y_pred==y_true))/len(y_true)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:16:25.213225Z","iopub.execute_input":"2023-12-25T16:16:25.213566Z","iopub.status.idle":"2023-12-25T16:16:25.218959Z","shell.execute_reply.started":"2023-12-25T16:16:25.213538Z","shell.execute_reply":"2023-12-25T16:16:25.217826Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_0(torch.tensor([train_dataset['input_ids'][3]]).to(device))['logits']","metadata":{"execution":{"iopub.status.busy":"2023-12-26T18:58:16.368035Z","iopub.execute_input":"2023-12-26T18:58:16.368983Z","iopub.status.idle":"2023-12-26T18:58:17.784387Z","shell.execute_reply.started":"2023-12-26T18:58:16.368948Z","shell.execute_reply":"2023-12-26T18:58:17.783504Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"tensor([[  6.0232, -13.2564, -13.6209, -13.1209, -12.4737, -12.7266]],\n       device='cuda:0', grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"class EmotionData(Dataset):\n    def __init__(self,data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        input_ids = data['input_ids'][idx]\n        attention_mask = data['attention_mask'][idx]\n        labels = data['labels'][idx]\n        \n        return {'input_ids':torch.tensor(input_ids),'attention_mask':torch.tensor(attention_mask),'labels':torch.tensor(labels)}","metadata":{"execution":{"iopub.status.busy":"2023-12-26T18:50:03.881428Z","iopub.execute_input":"2023-12-26T18:50:03.882390Z","iopub.status.idle":"2023-12-26T18:50:03.888388Z","shell.execute_reply.started":"2023-12-26T18:50:03.882353Z","shell.execute_reply":"2023-12-26T18:50:03.887371Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 100\n})"},"metadata":{}}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_0.parameters(),lr=0.01)\nfor i in range(2):\n    model_0.train()\n    Y_pred = model_0(torch.as_tensor([train_dataset['input_ids'][i]]).to(device))\n    print(Y_pred)\n    loss = loss_fn(Y_pred['logits'],torch.as_tensor([train_dataset['labels'][i]]).to(device))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\nprint(loss)\n#     print(accuracy(Y_pred,F.one_hot(torch.as_tensor(train_dataset['labels'][i])).to(device)))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T18:43:33.609147Z","iopub.execute_input":"2023-12-26T18:43:33.609888Z","iopub.status.idle":"2023-12-26T18:43:42.327879Z","shell.execute_reply.started":"2023-12-26T18:43:33.609851Z","shell.execute_reply":"2023-12-26T18:43:42.326944Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4238,  0.1265, -0.1755,  0.6909,  0.1299, -0.9170]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.2364,  0.6878,  0.0766, -0.1047,  0.4328,  0.0930]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\ntensor(2.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\nSequenceClassifierOutput(loss=None, logits=tensor([[-12.6143,   5.4391,   4.9107,   5.8035,   5.1901,   4.1955]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\nSequenceClassifierOutput(loss=None, logits=tensor([[-7.9504,  0.5234,  0.0311,  0.7315, -0.4870, -1.3021]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\ntensor(9.6881, device='cuda:0', grad_fn=<NllLossBackward0>)\nSequenceClassifierOutput(loss=None, logits=tensor([[-3.4945, -3.8889, -4.4120, -3.9167, -4.3108, -4.2226]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\nSequenceClassifierOutput(loss=None, logits=tensor([[ 1.4728, -8.3717, -9.1003, -9.0258, -8.4752, -8.1132]],\n       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\ntensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.squeeze(F.one_hot(torch.as_tensor(train_dataset['labels'][4]),num_classes=6).to(device))","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:16:40.533296Z","iopub.execute_input":"2023-12-25T16:16:40.533615Z","iopub.status.idle":"2023-12-25T16:16:40.552138Z","shell.execute_reply.started":"2023-12-25T16:16:40.533591Z","shell.execute_reply":"2023-12-25T16:16:40.551153Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 0, 1, 0, 0], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"Y_pred = model_0(torch.as_tensor([train_dataset['input_ids'][3]]).to(device))\nloss  = loss_fn(Y_pred,torch.as_tensor([train_dataset['labels'][3]]).to(device))\nprint(torch.squeeze(Y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:16:40.553442Z","iopub.execute_input":"2023-12-25T16:16:40.553734Z","iopub.status.idle":"2023-12-25T16:16:42.080180Z","shell.execute_reply.started":"2023-12-25T16:16:40.553709Z","shell.execute_reply":"2023-12-25T16:16:42.079260Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"tensor([-14.8620,   6.5938, -12.7250, -13.9139, -14.3188, -13.8228],\n       device='cuda:0', grad_fn=<SqueezeBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"target = torch.randint(0, 10, (4,))\ntarget","metadata":{"execution":{"iopub.status.busy":"2023-12-25T16:16:42.081218Z","iopub.execute_input":"2023-12-25T16:16:42.081506Z","iopub.status.idle":"2023-12-25T16:16:42.089283Z","shell.execute_reply.started":"2023-12-25T16:16:42.081481Z","shell.execute_reply":"2023-12-25T16:16:42.088250Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([0, 2, 7, 8])"},"metadata":{}}]},{"cell_type":"code","source":"def ModelFit(model,train_dataset,test_dataset,epochs=3):\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n    lr_schedule = ReduceLROnPlateau(optimizer,'min',factor=0.1,patience=2)\n\n    for epoch in range(epochs):\n        for i in range(len(train_dataset)):\n            model.train()\n            Y_pred = model(torch.tensor([train_dataset['input_ids'][i]]).to(device))\n            loss  = loss_fn(Y_pred['logits'],torch.tensor([train_dataset['labels'][i]]).to(device))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        for j in range(len(test_dataset)):\n            with torch.no_grad():\n                model.eval()\n                Y_pred_test = model(torch.tensor([test_dataset['input_ids'][j]]).to(device))\n                loss_test = loss_fn(Y_pred_test['logits'],torch.tensor([test_dataset['labels'][j]]).to(device))\n        \n        \n        print(\"Train Loss:\",loss,\"Test Loss:\",loss_test)\n        lr_schedule.step(loss_test)\n        if loss < 1 and loss_test < 1:\n            break\n            \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:03:37.963736Z","iopub.execute_input":"2023-12-26T19:03:37.964121Z","iopub.status.idle":"2023-12-26T19:03:37.973980Z","shell.execute_reply.started":"2023-12-26T19:03:37.964092Z","shell.execute_reply":"2023-12-26T19:03:37.972975Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# model_1 = ModelFit(model_0,train_dataset_d,test_dataset_d,epochs=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:03:42.617748Z","iopub.execute_input":"2023-12-26T19:03:42.618569Z","iopub.status.idle":"2023-12-26T19:04:29.521977Z","shell.execute_reply.started":"2023-12-26T19:03:42.618526Z","shell.execute_reply":"2023-12-26T19:04:29.521005Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Train Loss: tensor(3.6741, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(2.0280, device='cuda:0')\nTrain Loss: tensor(6.0211, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(0.3866, device='cuda:0')\nTrain Loss: tensor(2.4821, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(3.4167, device='cuda:0')\nTrain Loss: tensor(0.8295, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(2.2572, device='cuda:0')\nTrain Loss: tensor(4.2961, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(5.0312, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"# model_2 = ModelFit(model_1,train_dataset_d,test_dataset_d,epochs=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-25T18:08:41.162758Z","iopub.execute_input":"2023-12-25T18:08:41.163705Z","iopub.status.idle":"2023-12-25T18:52:04.196938Z","shell.execute_reply.started":"2023-12-25T18:08:41.163660Z","shell.execute_reply":"2023-12-25T18:52:04.195995Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Train Loss: tensor(4.5624, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(0.0013, device='cuda:0')\nTrain Loss: tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(2.4980, device='cuda:0')\nTrain Loss: tensor(0.3204, device='cuda:0', grad_fn=<NllLossBackward0>) Test Loss: tensor(0.0708, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install -q accelerate -U","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:34:49.159141Z","iopub.execute_input":"2023-12-27T08:34:49.159707Z","iopub.status.idle":"2023-12-27T08:35:01.086833Z","shell.execute_reply.started":"2023-12-27T08:34:49.159671Z","shell.execute_reply":"2023-12-27T08:35:01.085369Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"! pip install -q transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:35:22.379592Z","iopub.execute_input":"2023-12-27T08:35:22.379992Z","iopub.status.idle":"2023-12-27T08:35:34.141481Z","shell.execute_reply.started":"2023-12-27T08:35:22.379951Z","shell.execute_reply":"2023-12-27T08:35:34.140221Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer,TrainingArguments\n\nmodel = model.to(\"cuda\")\n# training_args = TrainingArguments(\n#     output_dir = './bert-mod',\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n#     fp16=False, # Overflows with fp16\n#     learning_rate=0.01,\n#     num_train_epochs=5,\n#     # logging & evaluation strategies\n# #     logging_strategy=\"steps\",\n# #     logging_steps=500,\n# #     evaluation_strategy=\"epoch\",\n# #     save_strategy=\"epoch\",\n# #     save_total_limit=2,\n# #     load_best_model_at_end=True,\n# #     push_to_hub=False,\n# )\n\ntrainer = Trainer(\n    model=model,\n    train_dataset = train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:37:01.037575Z","iopub.execute_input":"2023-12-27T08:37:01.037992Z","iopub.status.idle":"2023-12-27T08:37:28.614492Z","shell.execute_reply.started":"2023-12-27T08:37:01.037960Z","shell.execute_reply":"2023-12-27T08:37:28.612884Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1166, in init\n    wi.setup(kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 306, in setup\n    wandb_login._login(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 298, in _login\n    wlogin.prompt_api_key()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 221, in prompt_api_key\n    key, status = self._prompt_api_key()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 201, in _prompt_api_key\n    key = apikey.prompt_api_key(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/apikey.py\", line 144, in prompt_api_key\n    key = input_callback(api_ask).strip()\n  File \"/opt/conda/lib/python3.10/site-packages/click/termui.py\", line 164, in prompt\n    value = prompt_func(prompt)\n  File \"/opt/conda/lib/python3.10/site-packages/click/termui.py\", line 147, in prompt_func\n    raise Abort() from None\nclick.exceptions.Abort\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1165\u001b[0m wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[0;32m-> 1166\u001b[0m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m wi\u001b[38;5;241m.\u001b[39msettings\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:306\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings\u001b[38;5;241m.\u001b[39m_offline \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings\u001b[38;5;241m.\u001b[39m_noop:\n\u001b[0;32m--> 306\u001b[0m     \u001b[43mwandb_login\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43manonymous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manonymous\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_warning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_silent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# apply updated global state after login was handled\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:298\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m--> 298\u001b[0m     \u001b[43mwlogin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# make sure login credentials get to the backend\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:221\u001b[0m, in \u001b[0;36m_WandbLogin.prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt_api_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     key, status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m ApiKeyStatus\u001b[38;5;241m.\u001b[39mNOTTY:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:201\u001b[0m, in \u001b[0;36m_WandbLogin._prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mapikey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_offline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# invalid key provided, try again\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/apikey.py:144\u001b[0m, in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    141\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermlog(\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can find your API key in your browser here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/authorize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[0;32m--> 144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43minput_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_ask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    145\u001b[0m write_key(settings, key, api\u001b[38;5;241m=\u001b[39mapi)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/click/termui.py:164\u001b[0m, in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/click/termui.py:147\u001b[0m, in \u001b[0;36mprompt.<locals>.prompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    146\u001b[0m     echo(\u001b[38;5;28;01mNone\u001b[39;00m, err\u001b[38;5;241m=\u001b[39merr)\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Abort() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mAbort\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 28\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# training_args = TrainingArguments(\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     output_dir = './bert-mod',\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     per_device_train_batch_size=8,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# #     push_to_hub=False,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     22\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     23\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m train_dataset,\n\u001b[1;32m     24\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[1;32m     25\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1772\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[1;32m   1770\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mignore_data_skip:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_callback.py:370\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    369\u001b[0m     control\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_callback.py:414\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:767\u001b[0m, in \u001b[0;36mWandbCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m     args\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized:\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:740\u001b[0m, in \u001b[0;36mWandbCallback.setup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m         init_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mrun_name\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWANDB_PROJECT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuggingface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# add config parameters (run may have been created manually)\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate(combined_dict, allow_val_change\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1208\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             wandb\u001b[38;5;241m.\u001b[39mtermerror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbnormal program exit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1207\u001b[0m             os\u001b[38;5;241m.\u001b[39m_exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror_seen\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n","\u001b[0;31mError\u001b[0m: An unexpected error occurred"],"ename":"Error","evalue":"An unexpected error occurred","output_type":"error"}]},{"cell_type":"code","source":"torch.save(model_2.state_dict(),\"model_gpu.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-12-25T18:54:37.014596Z","iopub.execute_input":"2023-12-25T18:54:37.015022Z","iopub.status.idle":"2023-12-25T18:54:37.644628Z","shell.execute_reply.started":"2023-12-25T18:54:37.014992Z","shell.execute_reply":"2023-12-25T18:54:37.643814Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_2.to(\"cpu\")\ntorch.save(model_2.state_dict(),\"model_cpu.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-12-25T18:54:41.118080Z","iopub.execute_input":"2023-12-25T18:54:41.118434Z","iopub.status.idle":"2023-12-25T18:54:42.360099Z","shell.execute_reply.started":"2023-12-25T18:54:41.118407Z","shell.execute_reply":"2023-12-25T18:54:42.357838Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'model_gpu.pt')","metadata":{"execution":{"iopub.status.busy":"2023-12-25T18:56:04.281162Z","iopub.execute_input":"2023-12-25T18:56:04.281858Z","iopub.status.idle":"2023-12-25T18:56:04.288034Z","shell.execute_reply.started":"2023-12-25T18:56:04.281825Z","shell.execute_reply":"2023-12-25T18:56:04.287100Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_gpu.pt","text/html":"<a href='model_gpu.pt' target='_blank'>model_gpu.pt</a><br>"},"metadata":{}}]}]}