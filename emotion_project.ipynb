{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T08:18:42.554405Z",
          "iopub.execute_input": "2023-12-27T08:18:42.554811Z",
          "iopub.status.idle": "2023-12-27T08:18:54.208029Z",
          "shell.execute_reply.started": "2023-12-27T08:18:42.554780Z",
          "shell.execute_reply": "2023-12-27T08:18:54.206988Z"
        },
        "trusted": true,
        "id": "YPQhx6gpXNW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q sentencepiece"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T08:20:06.878918Z",
          "iopub.execute_input": "2023-12-27T08:20:06.879613Z",
          "iopub.status.idle": "2023-12-27T08:20:18.536988Z",
          "shell.execute_reply.started": "2023-12-27T08:20:06.879575Z",
          "shell.execute_reply": "2023-12-27T08:20:18.535795Z"
        },
        "trusted": true,
        "id": "gtICv3UzXNW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T08:20:18.656104Z",
          "iopub.execute_input": "2023-12-27T08:20:18.656519Z",
          "iopub.status.idle": "2023-12-27T08:20:22.531030Z",
          "shell.execute_reply.started": "2023-12-27T08:20:18.656488Z",
          "shell.execute_reply": "2023-12-27T08:20:22.530164Z"
        },
        "trusted": true,
        "id": "2PM92z3TXNXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=6)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T08:20:22.532583Z",
          "iopub.execute_input": "2023-12-27T08:20:22.532974Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7h7FT8bXNXA",
        "outputId": "8dd2287d-5eec-40fc-f919-42fc34059030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:37:12.656876Z",
          "iopub.execute_input": "2023-12-26T18:37:12.657817Z",
          "iopub.status.idle": "2023-12-26T18:37:12.664188Z",
          "shell.execute_reply.started": "2023-12-26T18:37:12.657784Z",
          "shell.execute_reply": "2023-12-26T18:37:12.663240Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFxJMD0LXNXB",
        "outputId": "ea4213bf-c0cd-47d8-bf59-1b869cb69d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q datasets"
      ],
      "metadata": {
        "id": "us-XbyWNXj9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# dataset = load_dataset(\"SetFit/emotion\")\n",
        "# from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"dair-ai/emotion\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:29:56.581372Z",
          "iopub.execute_input": "2023-12-26T18:29:56.581704Z",
          "iopub.status.idle": "2023-12-26T18:29:59.861998Z",
          "shell.execute_reply.started": "2023-12-26T18:29:56.581677Z",
          "shell.execute_reply": "2023-12-26T18:29:59.861107Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8oQIo9_XNXB",
        "outputId": "9d2cd2ed-5d3c-439a-9ed2-7cdaf2294d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for dair-ai/emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/dair-ai/emotion\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(['hello world'],padding=\"max_length\",truncation=True,return_tensors=\"pt\",max_length=128)\n",
        "inputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:21.505094Z",
          "iopub.execute_input": "2023-12-26T18:30:21.506098Z",
          "iopub.status.idle": "2023-12-26T18:30:21.519685Z",
          "shell.execute_reply.started": "2023-12-26T18:30:21.506062Z",
          "shell.execute_reply": "2023-12-26T18:30:21.518788Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju12cTejXNXC",
        "outputId": "b6a871f7-163e-44d9-f4ca-72504cb54969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 7592, 2088,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs['input_ids'])\n",
        "outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:25.996651Z",
          "iopub.execute_input": "2023-12-26T18:30:25.997009Z",
          "iopub.status.idle": "2023-12-26T18:30:26.594639Z",
          "shell.execute_reply.started": "2023-12-26T18:30:25.996981Z",
          "shell.execute_reply": "2023-12-26T18:30:26.593805Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLc_iZLmXNXD",
        "outputId": "ff3ee5a7-4f6d-49e4-c256-672b05bfc1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0892, -0.0927, -0.0218,  0.0724, -0.3068, -0.1945]],\n",
              "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:36.804675Z",
          "iopub.execute_input": "2023-12-26T18:30:36.805499Z",
          "iopub.status.idle": "2023-12-26T18:30:36.812241Z",
          "shell.execute_reply.started": "2023-12-26T18:30:36.805464Z",
          "shell.execute_reply": "2023-12-26T18:30:36.810764Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8uNG5CXNXD",
        "outputId": "bab8042b-8e29-4145-ba84-c70c3fe1338f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(sample,padding=\"max_length\"):\n",
        "#     inputs = [item for item in sample['text']]\n",
        "\n",
        "    X = tokenizer(text_target=sample['text'],padding=padding,max_length=128,truncation=True)\n",
        "\n",
        "    X[\"labels\"] = sample[\"label\"]\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:40.456374Z",
          "iopub.execute_input": "2023-12-26T18:30:40.456735Z",
          "iopub.status.idle": "2023-12-26T18:30:40.462101Z",
          "shell.execute_reply.started": "2023-12-26T18:30:40.456707Z",
          "shell.execute_reply": "2023-12-26T18:30:40.461099Z"
        },
        "trusted": true,
        "id": "ej3yzmTgXNXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dataset['train'][:1000]\n",
        "# dataset['train'] = dataset['train'][:2000]\n",
        "# dataset['test'] = dataset['test'][:1000]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T17:52:03.730877Z",
          "iopub.execute_input": "2023-12-26T17:52:03.731450Z",
          "iopub.status.idle": "2023-12-26T17:52:03.742558Z",
          "shell.execute_reply.started": "2023-12-26T17:52:03.731422Z",
          "shell.execute_reply": "2023-12-26T17:52:03.741764Z"
        },
        "trusted": true,
        "id": "3OIAlkPRXNXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train'].map(process_data,batched=True,remove_columns=['text','label'])\n",
        "test_dataset = dataset['test'].map(process_data,batched=True,remove_columns=['text','label'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:43.651600Z",
          "iopub.execute_input": "2023-12-26T18:30:43.651963Z",
          "iopub.status.idle": "2023-12-26T18:30:57.599996Z",
          "shell.execute_reply.started": "2023-12-26T18:30:43.651931Z",
          "shell.execute_reply": "2023-12-26T18:30:57.599200Z"
        },
        "trusted": true,
        "id": "VBHc7qBzXNXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(train_dataset['input_ids'][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:30:59.681234Z",
          "iopub.execute_input": "2023-12-26T18:30:59.681718Z",
          "iopub.status.idle": "2023-12-26T18:31:01.108686Z",
          "shell.execute_reply.started": "2023-12-26T18:30:59.681680Z",
          "shell.execute_reply": "2023-12-26T18:31:01.107781Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj-EzhLKXNXE",
        "outputId": "a6643269-77ae-4065-9c53-ee66d4abaa80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  1045,  2134,  2102,  2514, 26608,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([train_dataset['input_ids'][0]]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:31:05.540777Z",
          "iopub.execute_input": "2023-12-26T18:31:05.541267Z",
          "iopub.status.idle": "2023-12-26T18:31:07.422169Z",
          "shell.execute_reply.started": "2023-12-26T18:31:05.541233Z",
          "shell.execute_reply": "2023-12-26T18:31:07.421049Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvnkai5dXNXF",
        "outputId": "47debd59-3eca-474a-c9a7-a43327cffeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-0.1404, -0.0835,  0.0357,  0.0351, -0.3184, -0.1182]],\n",
              "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_d = train_dataset.select(range(100))\n",
        "test_dataset_d = test_dataset.select(range(100))\n",
        "\n",
        "train_dataset_d"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:44:21.410295Z",
          "iopub.execute_input": "2023-12-26T18:44:21.410640Z",
          "iopub.status.idle": "2023-12-26T18:44:21.424843Z",
          "shell.execute_reply.started": "2023-12-26T18:44:21.410611Z",
          "shell.execute_reply": "2023-12-26T18:44:21.423972Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGVEoxGFXNXF",
        "outputId": "211a7a1d-10e0-4ff5-f59a-5e57a9bbb044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self,model,num_classes):\n",
        "        super(BertClassifier,self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:42:17.913881Z",
          "iopub.execute_input": "2023-12-26T18:42:17.914717Z",
          "iopub.status.idle": "2023-12-26T18:42:17.919674Z",
          "shell.execute_reply.started": "2023-12-26T18:42:17.914681Z",
          "shell.execute_reply": "2023-12-26T18:42:17.918753Z"
        },
        "trusted": true,
        "id": "PWiItCiaXNXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = BertClassifier(model,6)\n",
        "model_0.to(device)\n",
        "print(model_0.parameters)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:42:19.739138Z",
          "iopub.execute_input": "2023-12-26T18:42:19.739503Z",
          "iopub.status.idle": "2023-12-26T18:42:19.750402Z",
          "shell.execute_reply.started": "2023-12-26T18:42:19.739475Z",
          "shell.execute_reply": "2023-12-26T18:42:19.749369Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP132-nnXNXG",
        "outputId": "2b4c9aff-f069-450f-cf2d-f16278fd8a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of BertClassifier(\n",
            "  (model): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-11): 12 x BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
            "  )\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred,y_true):\n",
        "    return sum((y_pred==y_true))/len(y_true)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T16:16:25.213225Z",
          "iopub.execute_input": "2023-12-25T16:16:25.213566Z",
          "iopub.status.idle": "2023-12-25T16:16:25.218959Z",
          "shell.execute_reply.started": "2023-12-25T16:16:25.213538Z",
          "shell.execute_reply": "2023-12-25T16:16:25.217826Z"
        },
        "trusted": true,
        "id": "GDdkRZ7vXNXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(torch.tensor([train_dataset['input_ids'][3]]).to(device))['logits']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:58:16.368035Z",
          "iopub.execute_input": "2023-12-26T18:58:16.368983Z",
          "iopub.status.idle": "2023-12-26T18:58:17.784387Z",
          "shell.execute_reply.started": "2023-12-26T18:58:16.368948Z",
          "shell.execute_reply": "2023-12-26T18:58:17.783504Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IvtLDaPXNXG",
        "outputId": "bfe956f1-9a10-4a81-c55b-aeea205cb1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1056, -0.1288,  0.0084,  0.0593, -0.3612, -0.1320]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionData(Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        input_ids = data['input_ids'][idx]\n",
        "        attention_mask = data['attention_mask'][idx]\n",
        "        labels = data['labels'][idx]\n",
        "\n",
        "        return {'input_ids':torch.tensor(input_ids),'attention_mask':torch.tensor(attention_mask),'labels':torch.tensor(labels)}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T18:50:03.881428Z",
          "iopub.execute_input": "2023-12-26T18:50:03.882390Z",
          "iopub.status.idle": "2023-12-26T18:50:03.888388Z",
          "shell.execute_reply.started": "2023-12-26T18:50:03.882353Z",
          "shell.execute_reply": "2023-12-26T18:50:03.887371Z"
        },
        "trusted": true,
        "id": "kUxu6H90XNXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers[torch]"
      ],
      "metadata": {
        "id": "D2gc0UwkYeuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q accelerate -U"
      ],
      "metadata": {
        "id": "B-Owmcb3YWTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer,TrainingArguments\n",
        "\n",
        "model = model.to(\"cuda\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './bert-mod',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    fp16=False, # Overflows with fp16\n",
        "    learning_rate=0.01,\n",
        "    num_train_epochs=5,\n",
        "    # logging & evaluation strategies\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T19:05:43.457441Z",
          "iopub.execute_input": "2023-12-26T19:05:43.458152Z",
          "iopub.status.idle": "2023-12-26T19:05:56.776170Z",
          "shell.execute_reply.started": "2023-12-26T19:05:43.458121Z",
          "shell.execute_reply": "2023-12-26T19:05:56.774495Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "Mr2A07dCXNXI",
        "outputId": "3ec6c71f-9aa1-4fee-a9ce-9e338f5a7a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6000/6000 21:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.781800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.359200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.296000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.243000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.151700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.166300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.171200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.158200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.110200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.118100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.098800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6000, training_loss=0.23016818682352702, metrics={'train_runtime': 1275.2171, 'train_samples_per_second': 37.641, 'train_steps_per_second': 4.705, 'total_flos': 3157446057984000.0, 'train_loss': 0.23016818682352702, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./model/\")"
      ],
      "metadata": {
        "id": "bA1aKXbkh1nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(\"cpu\")\n",
        "model.save_pretrained(\"./cpu model/\")"
      ],
      "metadata": {
        "id": "B7qJvJeqnqbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fhyM0RGnvW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}